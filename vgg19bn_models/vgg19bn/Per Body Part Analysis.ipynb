{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai: 1.0.52\n",
      "cuda: False\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from fastai.vision import *\n",
    "from fastai.widgets import *\n",
    "from fastai.callbacks import * \n",
    "import shutil\n",
    "import fastai\n",
    "print(f'fastai: {fastai.__version__}')\n",
    "print(f'cuda: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.DEFAULT_CONFIG = {\n",
    "        'data_path': './../data/MURA-v1.1/',\n",
    "        'model_path': './models/'\n",
    "    }\n",
    "\n",
    "Config.create('/tmp/myconfig.yml')\n",
    "Config.DEFAULT_CONFIG_PATH = '/tmp/myconfig.yml'\n",
    "\n",
    "path = Config.data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 320\n",
    "bs = 32\n",
    "\n",
    "np.random.seed(24)\n",
    "\n",
    "def create_from_ll(lls:LabelLists, bs:int=64, val_bs:int=None, ds_tfms:Optional[TfmList]=None,\n",
    "                num_workers:int=defaults.cpus, dl_tfms:Optional[Collection[Callable]]=None, device:torch.device=None,\n",
    "                test:Optional[PathOrStr]=None, collate_fn:Callable=data_collate, size:int=None, no_check:bool=False,\n",
    "                resize_method:ResizeMethod=None, mult:int=None, padding_mode:str='reflection',\n",
    "                mode:str='bilinear', tfm_y:bool=False)->'ImageDataBunch':\n",
    "    \"Create an `ImageDataBunch` from `LabelLists` `lls` with potential `ds_tfms`.\"\n",
    "    lls = lls.transform(tfms=get_transforms(do_flip=True, max_rotate=30, max_warp=0.0, p_lighting=0, xtra_tfms=[]), size=size, resize_method=resize_method, mult=mult, padding_mode=padding_mode,\n",
    "                        mode=mode, tfm_y=tfm_y)\n",
    "    \n",
    "    return lls.databunch(bs=bs, val_bs=bs, dl_tfms=dl_tfms, num_workers=num_workers, collate_fn=collate_fn,\n",
    "                         device=device, no_check=True)\n",
    "\n",
    "src = (ImageList.from_df(df=pd.read_csv('all_WRIST.csv'), path='../data/MURA-v1.1/data2/', folder=None, suffix='', cols=0)\n",
    "                .split_from_df(\"is_valid\")\n",
    "                .label_from_df(label_delim=None, cols=1))\n",
    "data = create_from_ll(src, size = size, bs = bs).normalize(imagenet_stats)\n",
    "\n",
    "kappa = KappaScore()\n",
    "kappa.weights = \"quadratic\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (9752 items)\n",
       "x: ImageList\n",
       "Image (3, 320, 320),Image (3, 320, 320),Image (3, 320, 320),Image (3, 320, 320),Image (3, 320, 320)\n",
       "y: CategoryList\n",
       "0,0,0,0,0\n",
       "Path: ../data/MURA-v1.1/data2;\n",
       "\n",
       "Valid: LabelList (659 items)\n",
       "x: ImageList\n",
       "Image (3, 320, 320),Image (3, 320, 320),Image (3, 320, 320),Image (3, 320, 320),Image (3, 320, 320)\n",
       "y: CategoryList\n",
       "0,0,0,0,0\n",
       "Path: ../data/MURA-v1.1/data2;\n",
       "\n",
       "Test: None, model=Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace)\n",
       "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (25): ReLU(inplace)\n",
       "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace)\n",
       "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (35): ReLU(inplace)\n",
       "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (38): ReLU(inplace)\n",
       "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace)\n",
       "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (45): ReLU(inplace)\n",
       "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (48): ReLU(inplace)\n",
       "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (51): ReLU(inplace)\n",
       "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten()\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5)\n",
       "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function error_rate at 0x7ff6e92aa2f0>, <function accuracy at 0x7ff6e92aa158>, KappaScore(weights='quadratic')], true_wd=True, bn_wd=True, wd=0.1, train_bn=True, path=PosixPath('../data/MURA-v1.1/data2'), model_dir='./models/', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace)\n",
       "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ReLU(inplace)\n",
       "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): ReLU(inplace)\n",
       "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): ReLU(inplace)\n",
       "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU(inplace)\n",
       "  (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "), Sequential(\n",
       "  (0): ReLU(inplace)\n",
       "  (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): ReLU(inplace)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): ReLU(inplace)\n",
       "  (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU(inplace)\n",
       "  (11): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): ReLU(inplace)\n",
       "  (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): ReLU(inplace)\n",
       "  (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): ReLU(inplace)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (23): ReLU(inplace)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): ReLU(inplace)\n",
       "  (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): ReLU(inplace)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "), Sequential(\n",
       "  (0): AdaptiveAvgPool2d(output_size=1)\n",
       "  (1): AdaptiveMaxPool2d(output_size=1)\n",
       "  (2): Flatten()\n",
       "  (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Dropout(p=0.25)\n",
       "  (5): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Dropout(p=0.5)\n",
       "  (9): Linear(in_features=512, out_features=2, bias=True)\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner = cnn_learner(data, models.vgg19_bn, metrics=[error_rate, accuracy, kappa], wd=0.1, model_dir=\"./models/\").to_fp32()\n",
    "# #learner.unfreeze()\n",
    "# learner.fit_one_cycle(5,max_lr=1e-3, callbacks=[ShowGraph(learner) ,SaveModelCallback(learner)])\n",
    "\n",
    "learner.load('vgg19bn-WRISTfullval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interp = ClassificationInterpretation.from_learner(learner)\n",
    "\n",
    "# losses,idxs = interp.top_losses()\n",
    "\n",
    "# len(data.valid_ds)==len(losses)==len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interp.plot_top_losses(30, figsize=(30,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds,val_targets = learner.get_preds() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722619652748108\n"
     ]
    }
   ],
   "source": [
    "print(float(val_preds[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WRIST_patient11347_study2_negative_image1.png'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "files = [f for f in listdir('../data/MURA-v1.1/data2/valid/0/') if isfile(join('../data/MURA-v1.1/data2/valid/0/', f)) and \"WRIST\" in f]\n",
    "files += [f for f in listdir('../data/MURA-v1.1/data2/valid/1/') if isfile(join('../data/MURA-v1.1/data2/valid/1/', f)) and \"WRIST\" in f]\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = []\n",
    "studies_labels = []\n",
    "for file in files:\n",
    "    study = file[:-11]\n",
    "    if study not in studies:\n",
    "        studies.append(study)\n",
    "        if 'negative' in study:\n",
    "            studies_labels.append(0)\n",
    "        else:\n",
    "            studies_labels.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659\n",
      "659\n"
     ]
    }
   ],
   "source": [
    "# learner.get_preds('../data/MURA-v1.1/data2/valid/0/ELBOW_patient11860_study1_negative_image1.png')\n",
    "\n",
    "# img = open_image('../data/MURA-v1.1/data2/valid/0/ELBOW_patient11860_study1_negative_image1.png')\n",
    "# img\n",
    "# learner.predict(img)\n",
    "\n",
    "print(len(val_preds))\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_actual = dict()\n",
    "for study in studies:\n",
    "    if 'negative' in study:\n",
    "        study_actual[study] = 0\n",
    "    else:\n",
    "        study_actual[study] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_dict = dict()\n",
    "for study in studies:\n",
    "    if study not in study_dict:\n",
    "        study_dict[study] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_count = 0\n",
    "for file in files:\n",
    "    study = file[:-11]\n",
    "    study_dict[study].append(float(val_preds[file_count][1]))\n",
    "    file_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_preds = dict()\n",
    "for study in study_dict:\n",
    "    combined_pr = sum(study_dict[study])/len(study_dict[study])\n",
    "    if combined_pr >= 0.5:\n",
    "        study_preds[study] = 1\n",
    "    else:\n",
    "        study_preds[study] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "print(len(study_actual))\n",
    "print(len(study_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "please = 0\n",
    "for i in study_actual:\n",
    "    if study_actual[i] == study_preds[i]:\n",
    "        please += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8860759493670886"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "please/len(study_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kappa\n",
    "actual_list = []\n",
    "pred_list = []\n",
    "for i in study_actual:\n",
    "    actual_list.append(study_actual[i])\n",
    "    pred_list.append(study_preds[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_o = 0\n",
    "p_e = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8860759493670886"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreed = 0\n",
    "for i in range(len(actual_list)):\n",
    "    if actual_list[i] == pred_list[i]:\n",
    "        agreed += 1\n",
    "p_o = agreed/len(actual_list)\n",
    "p_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.527942459363706"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_yes = sum(actual_list)/len(actual_list)\n",
    "pred_yes = sum(pred_list)/len(pred_list)\n",
    "\n",
    "actual_no = 1-sum(actual_list)/len(actual_list)\n",
    "pred_no = 1-sum(pred_list)/len(pred_list)\n",
    "\n",
    "p_e = actual_yes*pred_yes + actual_no*pred_no\n",
    "p_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = (p_o-p_e)/(1-p_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7586649066566094"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
